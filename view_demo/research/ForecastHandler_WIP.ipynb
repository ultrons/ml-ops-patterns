{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be67f972-05e2-47fe-a037-6276d2a3fbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import logging\n",
    "\n",
    "import torch\n",
    "from ts.torch_handler.base_handler import BaseHandler\n",
    "\n",
    "import copy\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "import torch\n",
    "\n",
    "from pytorch_forecasting import Baseline, TemporalFusionTransformer, TimeSeriesDataSet\n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fe70d2eb-f9fd-4f09-aa55-cf27d2825f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "59f19943-e95b-4f6d-87c4-166756ae8394",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ForcastHandler(BaseHandler):\n",
    "    def __init__(self):\n",
    "        super(ForcastHandler, self).__init__()\n",
    "        self.initialized = False\n",
    "        \n",
    "    def initialize(self, ctx):\n",
    "        \"\"\" Loads the model.pt file and initialized the model object.\n",
    "        Instantiates Tokenizer for preprocessor to use\n",
    "        Loads labels to name mapping file for post-processing inference response\n",
    "        \"\"\"\n",
    "        self.manifest = ctx.manifest\n",
    "\n",
    "        properties = ctx.system_properties\n",
    "        model_dir = properties.get(\"model_dir\")\n",
    "        self.device = torch.device(\"cuda:\" + str(properties.get(\"gpu_id\")) if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        # Read model serialize/pt file\n",
    "        serialized_file = self.manifest[\"model\"][\"serializedFile\"]\n",
    "        model_pt_path = os.path.join(model_dir, serialized_file)\n",
    "        print(\"DEBUG:\", model_pt_path)\n",
    "        if not os.path.isfile(model_pt_path):\n",
    "            raise RuntimeError(\"Missing the model.pt or pytorch_model.bin file\")\n",
    "        \n",
    "        # Load model\n",
    "        self.model = torch.load(model_pt_path)\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "        logger.debug('Forecasting model from path {0} loaded successfully'.format(model_dir))\n",
    "        \n",
    "\n",
    "        self.initialized = True\n",
    "        \n",
    "    def preprocess(self, data):\n",
    "        data = data[0]['data']\n",
    "        max_prediction_length = 24\n",
    "        max_encoder_length = 120\n",
    "        print(\"DEBUG:\", type(data))\n",
    "        data = pd.DataFrame.from_dict(data)\n",
    "        print(data.columns)\n",
    "        print(data.describe())\n",
    "        data[\"time_idx\"] =  data[\"Date_Time\"].dt.year*365*24 + data[\"Date_Time\"].dt.dayofyear * 24 + data[\"Date_Time\"].dt.hour\n",
    "        #data[\"time_idx\"] =  data[\"Date_Time\"].dt.hour\n",
    "       \n",
    "        data[\"time_idx\"] -= data[\"time_idx\"].min()\n",
    "        training_cutoff = data[\"time_idx\"].max() - 100*max_prediction_length\n",
    "\n",
    "        time_varying_known_reals = [\n",
    "            'p__mbar',\n",
    "            'Tpot__K',\n",
    "            'Tdew__degC',\n",
    "            'rh__percent',\n",
    "            'VPmax__mbar',\n",
    "            'VPact__mbar',\n",
    "            'VPdef__mbar',\n",
    "            'sh__g_per_kg',\n",
    "            'H2OC__mmol_per_mol',\n",
    "            'rho__gm_per_cubic_m',\n",
    "            'wv__m_per_s',\n",
    "            'max_w__vm_per_s',\n",
    "            'wd__deg',\n",
    "            'time_idx'\n",
    "        ]\n",
    "        inference_set = TimeSeriesDataSet(\n",
    "            data,\n",
    "            time_idx=\"time_idx\",\n",
    "            target=\"T__degC\",\n",
    "            #categorical_encoders={\"series\": NaNLabelEncoder().fit(data.series)},\n",
    "            group_ids=[\"series\"],\n",
    "            # only unknown variable is \"value\" - and N-Beats can also not take any additional variables\n",
    "            time_varying_unknown_reals=[\"T__degC\"],\n",
    "            time_varying_known_reals=time_varying_known_reals,\n",
    "            min_encoder_length=max_encoder_length // 2,  # keep encoder length long (as it is in the validation set)\n",
    "            max_encoder_length=max_encoder_length,\n",
    "            min_prediction_length=1,\n",
    "            max_prediction_length=max_prediction_length,\n",
    "            add_relative_time_idx=True,\n",
    "            add_target_scales=True,\n",
    "            add_encoder_length=True,\n",
    "            allow_missing_timesteps=True,\n",
    "        )\n",
    "\n",
    "        # create validation set (predict=True) which means to predict the last max_prediction_length points in time\n",
    "        # for each series\n",
    "        \n",
    "        return inference_set\n",
    "\n",
    "        # create dataloaders for model\n",
    "        batch_size = 128  # set this between 32 to 128        \n",
    "\n",
    "        def inference(self, inputs):\n",
    "            return model.predict(inputs)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "cb60631c-702e-4d8b-ae7a-632e3473590d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ts.torch_handler.unit_tests.test_utils.mock_context import MockContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "aeb20805-fe8e-4a02-b908-2422e3fb6dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id = 'pytorch-tpu-nfs'\n",
    "dataset_id = 'view_dataset'\n",
    "table_id = 'weather_time_series_named'\n",
    "location = 'us-central1'\n",
    "staging_bucket = 'automl-samples'\n",
    "experiment_prefix = 'pytorch-forecasting'\n",
    "from google.cloud import bigquery\n",
    "\n",
    "sql = f\"\"\"\n",
    "SELECT *\n",
    "FROM  `{project_id}.{dataset_id}.{table_id}`\n",
    "LIMIT 240\n",
    "\"\"\"\n",
    "client = bigquery.Client(location=location, project=project_id)\n",
    "query_job = client.query(\n",
    "  sql,\n",
    "  # Location must match that of the dataset(s) referenced in the query.\n",
    "  location=location,\n",
    ")  # API request - starts the query\n",
    "\n",
    "data = query_job.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "081b6dac-213d-4de3-8f27-327f53c0fc0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p__mbar</th>\n",
       "      <th>T__degC</th>\n",
       "      <th>Tpot__K</th>\n",
       "      <th>Tdew__degC</th>\n",
       "      <th>rh__percent</th>\n",
       "      <th>VPmax__mbar</th>\n",
       "      <th>VPact__mbar</th>\n",
       "      <th>VPdef__mbar</th>\n",
       "      <th>sh__g_per_kg</th>\n",
       "      <th>H2OC__mmol_per_mol</th>\n",
       "      <th>rho__gm_per_cubic_m</th>\n",
       "      <th>wv__m_per_s</th>\n",
       "      <th>max_w__vm_per_s</th>\n",
       "      <th>wd__deg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>240.000000</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>240.00000</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>240.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>997.594750</td>\n",
       "      <td>-8.572583</td>\n",
       "      <td>264.774375</td>\n",
       "      <td>-10.588625</td>\n",
       "      <td>85.743542</td>\n",
       "      <td>3.461500</td>\n",
       "      <td>2.959042</td>\n",
       "      <td>0.502875</td>\n",
       "      <td>1.849125</td>\n",
       "      <td>2.968667</td>\n",
       "      <td>1312.651042</td>\n",
       "      <td>1.31275</td>\n",
       "      <td>2.300292</td>\n",
       "      <td>166.619458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.425166</td>\n",
       "      <td>5.704442</td>\n",
       "      <td>5.852470</td>\n",
       "      <td>5.670704</td>\n",
       "      <td>8.819942</td>\n",
       "      <td>1.365469</td>\n",
       "      <td>1.207863</td>\n",
       "      <td>0.451055</td>\n",
       "      <td>0.762419</td>\n",
       "      <td>1.222751</td>\n",
       "      <td>32.001549</td>\n",
       "      <td>1.28447</td>\n",
       "      <td>1.870730</td>\n",
       "      <td>80.410988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>984.740000</td>\n",
       "      <td>-22.760000</td>\n",
       "      <td>250.850000</td>\n",
       "      <td>-24.800000</td>\n",
       "      <td>48.390000</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>0.810000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.810000</td>\n",
       "      <td>1259.560000</td>\n",
       "      <td>0.05000</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>994.012500</td>\n",
       "      <td>-12.640000</td>\n",
       "      <td>260.517500</td>\n",
       "      <td>-14.675000</td>\n",
       "      <td>84.300000</td>\n",
       "      <td>2.307500</td>\n",
       "      <td>1.952500</td>\n",
       "      <td>0.230000</td>\n",
       "      <td>1.215000</td>\n",
       "      <td>1.950000</td>\n",
       "      <td>1290.497500</td>\n",
       "      <td>0.55000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>139.775000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>998.495000</td>\n",
       "      <td>-7.860000</td>\n",
       "      <td>265.410000</td>\n",
       "      <td>-10.100000</td>\n",
       "      <td>88.600000</td>\n",
       "      <td>3.375000</td>\n",
       "      <td>2.830000</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>1.765000</td>\n",
       "      <td>2.835000</td>\n",
       "      <td>1310.285000</td>\n",
       "      <td>0.90000</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>178.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1002.270000</td>\n",
       "      <td>-3.835000</td>\n",
       "      <td>269.447500</td>\n",
       "      <td>-5.815000</td>\n",
       "      <td>91.100000</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>3.952500</td>\n",
       "      <td>0.532500</td>\n",
       "      <td>2.465000</td>\n",
       "      <td>3.957500</td>\n",
       "      <td>1336.457500</td>\n",
       "      <td>1.55250</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>214.075000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1004.600000</td>\n",
       "      <td>-0.700000</td>\n",
       "      <td>273.480000</td>\n",
       "      <td>-2.310000</td>\n",
       "      <td>96.200000</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>5.150000</td>\n",
       "      <td>2.860000</td>\n",
       "      <td>3.260000</td>\n",
       "      <td>5.230000</td>\n",
       "      <td>1382.100000</td>\n",
       "      <td>7.29000</td>\n",
       "      <td>10.380000</td>\n",
       "      <td>356.400000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           p__mbar     T__degC     Tpot__K  Tdew__degC  rh__percent  \\\n",
       "count   240.000000  240.000000  240.000000  240.000000   240.000000   \n",
       "mean    997.594750   -8.572583  264.774375  -10.588625    85.743542   \n",
       "std       5.425166    5.704442    5.852470    5.670704     8.819942   \n",
       "min     984.740000  -22.760000  250.850000  -24.800000    48.390000   \n",
       "25%     994.012500  -12.640000  260.517500  -14.675000    84.300000   \n",
       "50%     998.495000   -7.860000  265.410000  -10.100000    88.600000   \n",
       "75%    1002.270000   -3.835000  269.447500   -5.815000    91.100000   \n",
       "max    1004.600000   -0.700000  273.480000   -2.310000    96.200000   \n",
       "\n",
       "       VPmax__mbar  VPact__mbar  VPdef__mbar  sh__g_per_kg  \\\n",
       "count   240.000000   240.000000   240.000000    240.000000   \n",
       "mean      3.461500     2.959042     0.502875      1.849125   \n",
       "std       1.365469     1.207863     0.451055      0.762419   \n",
       "min       0.970000     0.810000     0.160000      0.510000   \n",
       "25%       2.307500     1.952500     0.230000      1.215000   \n",
       "50%       3.375000     2.830000     0.360000      1.765000   \n",
       "75%       4.600000     3.952500     0.532500      2.465000   \n",
       "max       5.800000     5.150000     2.860000      3.260000   \n",
       "\n",
       "       H2OC__mmol_per_mol  rho__gm_per_cubic_m  wv__m_per_s  max_w__vm_per_s  \\\n",
       "count          240.000000           240.000000    240.00000       240.000000   \n",
       "mean             2.968667          1312.651042      1.31275         2.300292   \n",
       "std              1.222751            32.001549      1.28447         1.870730   \n",
       "min              0.810000          1259.560000      0.05000         0.380000   \n",
       "25%              1.950000          1290.497500      0.55000         1.000000   \n",
       "50%              2.835000          1310.285000      0.90000         1.750000   \n",
       "75%              3.957500          1336.457500      1.55250         2.750000   \n",
       "max              5.230000          1382.100000      7.29000        10.380000   \n",
       "\n",
       "          wd__deg  \n",
       "count  240.000000  \n",
       "mean   166.619458  \n",
       "std     80.410988  \n",
       "min      0.120000  \n",
       "25%    139.775000  \n",
       "50%    178.650000  \n",
       "75%    214.075000  \n",
       "max    356.400000  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "1d49533c-4ca8-408a-babc-8ac304c502d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = data.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "a4ff18d0-3ce7-4c4b-8b74-bdce78f0eeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.DataFrame.from_dict(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "f564ba53-39be-492d-bb08-61de08783935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     2009-01-01 01:00:00+00:00\n",
       "1     2009-01-01 02:00:00+00:00\n",
       "2     2009-01-01 03:00:00+00:00\n",
       "3     2009-01-01 04:00:00+00:00\n",
       "4     2009-01-01 05:00:00+00:00\n",
       "                 ...           \n",
       "235   2009-01-10 20:00:00+00:00\n",
       "236   2009-01-10 21:00:00+00:00\n",
       "237   2009-01-10 22:00:00+00:00\n",
       "238   2009-01-10 23:00:00+00:00\n",
       "239   2009-01-11 00:00:00+00:00\n",
       "Name: Date_Time, Length: 240, dtype: datetime64[ns, UTC]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a['Date_Time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "fe1121ba-6635-4613-965a-82f280dada95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Handler\n",
    "def model_setup(dataframe):\n",
    "    context = MockContext(model_name=\"temp_forecasting\", model_dir='/home/jupyter/ml-ops-patterns/view_demo/research',)\n",
    "    sample = dataframe.to_dict()\n",
    "    return (context, sample)\n",
    "\n",
    "def test_initialize(model_setup):\n",
    "    model_context, _ = model_setup\n",
    "    handler = ForcastHandler()\n",
    "    handler.initialize(model_context)\n",
    "\n",
    "    assert(True)\n",
    "    return handler\n",
    "\n",
    "def test_handle(model_setup):\n",
    "    context, data = model_setup\n",
    "    handler = test_initialize(model_setup)\n",
    "    test_data = [{'data': data}] * 2\n",
    "    results = handler.handle(test_data, context)\n",
    "    #assert(len(results) == 2)\n",
    "    #assert('tiger_cat' in results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "11d40318-57f7-4734-8ee7-7f9ae0cda48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_model_setup = model_setup(data)\n",
    "#test_initialize(model_setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "ce63a03c-b0f4-48bf-a38f-c7d8b813edaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: /home/jupyter/ml-ops-patterns/view_demo/research/model.pt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.ForcastHandler at 0x7fd3ad358b90>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_initialize(_model_setup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "2e70660c-134b-48e4-95aa-7e53ed029a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: /home/jupyter/ml-ops-patterns/view_demo/research/model.pt\n",
      "DEBUG: <class 'dict'>\n",
      "Index(['series', 'Date_Time', 'p__mbar', 'T__degC', 'Tpot__K', 'Tdew__degC',\n",
      "       'rh__percent', 'VPmax__mbar', 'VPact__mbar', 'VPdef__mbar',\n",
      "       'sh__g_per_kg', 'H2OC__mmol_per_mol', 'rho__gm_per_cubic_m',\n",
      "       'wv__m_per_s', 'max_w__vm_per_s', 'wd__deg'],\n",
      "      dtype='object')\n",
      "           p__mbar     T__degC     Tpot__K  Tdew__degC  rh__percent  \\\n",
      "count   240.000000  240.000000  240.000000  240.000000   240.000000   \n",
      "mean    997.594750   -8.572583  264.774375  -10.588625    85.743542   \n",
      "std       5.425166    5.704442    5.852470    5.670704     8.819942   \n",
      "min     984.740000  -22.760000  250.850000  -24.800000    48.390000   \n",
      "25%     994.012500  -12.640000  260.517500  -14.675000    84.300000   \n",
      "50%     998.495000   -7.860000  265.410000  -10.100000    88.600000   \n",
      "75%    1002.270000   -3.835000  269.447500   -5.815000    91.100000   \n",
      "max    1004.600000   -0.700000  273.480000   -2.310000    96.200000   \n",
      "\n",
      "       VPmax__mbar  VPact__mbar  VPdef__mbar  sh__g_per_kg  \\\n",
      "count   240.000000   240.000000   240.000000    240.000000   \n",
      "mean      3.461500     2.959042     0.502875      1.849125   \n",
      "std       1.365469     1.207863     0.451055      0.762419   \n",
      "min       0.970000     0.810000     0.160000      0.510000   \n",
      "25%       2.307500     1.952500     0.230000      1.215000   \n",
      "50%       3.375000     2.830000     0.360000      1.765000   \n",
      "75%       4.600000     3.952500     0.532500      2.465000   \n",
      "max       5.800000     5.150000     2.860000      3.260000   \n",
      "\n",
      "       H2OC__mmol_per_mol  rho__gm_per_cubic_m  wv__m_per_s  max_w__vm_per_s  \\\n",
      "count          240.000000           240.000000    240.00000       240.000000   \n",
      "mean             2.968667          1312.651042      1.31275         2.300292   \n",
      "std              1.222751            32.001549      1.28447         1.870730   \n",
      "min              0.810000          1259.560000      0.05000         0.380000   \n",
      "25%              1.950000          1290.497500      0.55000         1.000000   \n",
      "50%              2.835000          1310.285000      0.90000         1.750000   \n",
      "75%              3.957500          1336.457500      1.55250         2.750000   \n",
      "max              5.230000          1382.100000      7.29000        10.380000   \n",
      "\n",
      "          wd__deg  \n",
      "count  240.000000  \n",
      "mean   166.619458  \n",
      "std     80.410988  \n",
      "min      0.120000  \n",
      "25%    139.775000  \n",
      "50%    178.650000  \n",
      "75%    214.075000  \n",
      "max    356.400000  \n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'stop_randomization'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_11893/2129196777.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_model_setup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_11893/2984712912.py\u001b[0m in \u001b[0;36mtest_handle\u001b[0;34m(model_setup)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mhandler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_setup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0;31m#assert(len(results) == 2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m#assert('tiger_cat' in results[0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/ts/torch_handler/base_handler.py\u001b[0m in \u001b[0;36mhandle\u001b[0;34m(self, data, context)\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m         \u001b[0mdata_preprocess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_explain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_11893/3324909607.py\u001b[0m in \u001b[0;36mpreprocess\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0madd_encoder_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0mallow_missing_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m             \u001b[0mstop_randomization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         )\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'stop_randomization'"
     ]
    }
   ],
   "source": [
    "test_handle(_model_setup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f040f958-3226-4e39-894c-cea12a522026",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b1ae0b-df1e-4b38-b83e-6a38c7c9e788",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-9.m82",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-9:m82"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

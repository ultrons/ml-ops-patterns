{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import NamedTuple\n",
    "\n",
    "\n",
    "from kfp import dsl\n",
    "from kfp.v2 import compiler\n",
    "from typing import NamedTuple\n",
    "from kfp.v2 import dsl\n",
    "from kfp.v2.dsl import (\n",
    "    component,\n",
    "    InputPath,\n",
    "    OutputPath,\n",
    "    Input,\n",
    "    Output,\n",
    "    Artifact,\n",
    "    Dataset,\n",
    "    Model,\n",
    "    ClassificationMetrics,\n",
    "    Metrics,\n",
    ")\n",
    "\n",
    "from kfp.v2.google.client import AIPlatformClient\n",
    "from view_demo.utils import get_project_id\n",
    "from google_cloud_pipeline_components import aiplatform as gcc_aip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = get_project_id()\n",
    "REGION = 'us-central1'\n",
    "CONTAINER_URI = 'gcr.io/pytorch-tpu-nfs/test-custom-container'\n",
    "SRC_ROOT = '..'\n",
    "PIPELINE_ROOT = 'gs://automl-samples/pipelines/staging'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    base_image=CONTAINER_URI,\n",
    "    output_component_file=f'{SRC_ROOT}/preprocess/preprocess.yaml',\n",
    ")\n",
    "def view_preprocess(\n",
    "    project_id: str,\n",
    "    raw_dataset: str,\n",
    "    out_dataset: OutputPath(),\n",
    "):\n",
    "    from view_demo.preprocess import create_dataset\n",
    "    bq_path = create_dataset(project_id=project_id, csv_path=raw_dataset)\n",
    "    with open(out_dataset, 'w') as f:\n",
    "        f.write(bq_path)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_mae: OutputPath(float),\n",
    "@component(\n",
    "    base_image=CONTAINER_URI,\n",
    "    output_component_file=f'{SRC_ROOT}/train/train.yaml',\n",
    ")\n",
    "def view_train(\n",
    "    project_id: str,\n",
    "    input_dataset_path: InputPath(),\n",
    "    metrics: Output[Metrics],\n",
    "    model: Output[Model],\n",
    "    experiment_prefix: str ,\n",
    "    staging_bucket: str = 'gs://automl-samples',\n",
    "    context_window: int = 24\n",
    "  \n",
    ") -> float :\n",
    "    print(locals())\n",
    "    from google.cloud import aiplatform\n",
    "    from datetime import datetime\n",
    "    import logging\n",
    "    with open(input_dataset_path) as f:\n",
    "        logging.info(f\"input_dataset is: {f.read()}\")\n",
    "    # Create and experiment tag\n",
    "    TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "    experiment_id = experiment_prefix + TIMESTAMP\n",
    "    run_id = f'context-window-{context_window}'\n",
    "    # Init AI Platform\n",
    "    aiplatform.init(\n",
    "        project=project_id,\n",
    "        staging_bucket=staging_bucket,\n",
    "        experiment=experiment_id\n",
    "    )\n",
    "\n",
    "    # Define the custom training job\n",
    "    job = aiplatform.CustomContainerTrainingJob(\n",
    "        display_name=\"view-training\",\n",
    "        container_uri='gcr.io/pytorch-tpu-nfs/test-custom-trainer:latest',\n",
    "        model_serving_container_image_uri=\"gcr.io/cloud-aiplatform/prediction/tf2-cpu.2-2:latest\",\n",
    "    )\n",
    "    logging.info(f\"Type of experiment_id :{type(experiment_id)}\")\n",
    "    logging.info(f\"Type of staging_bucket :{type(staging_bucket)}\")\n",
    "    logging.info(f\"Type of context_window :{type(context_window)}\")\n",
    "    model_obj = job.run(\n",
    "        replica_count=1, \n",
    "        model_display_name=\"temp-prediction\",\n",
    "        args=[\n",
    "            f'--experiment-id={experiment_id}', \n",
    "            f'--staging-bucket={staging_bucket}',\n",
    "            f'--context-window={context_window}'\n",
    "        ],\n",
    "        environment_variables={'AIP_MODEL_DIR': model.uri},\n",
    "        base_output_dir=os.path.dirname(model.uri)\n",
    "    )\n",
    "    \n",
    "    metrics_df = aiplatform.get_experiment_df(experiment_id)\n",
    "    val_mae = metrics_df.loc[metrics_df['run_name'] == run_id]['metric.val_mae'].values[-1]\n",
    "    val_mae = float(val_mae)\n",
    "    metrics.log_metric('val_mae', val_mae)\n",
    "    logging.info(f\"Mean Error is:{val_mae}\")\n",
    "    return val_mae\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    base_image=CONTAINER_URI,\n",
    "    output_component_file=f'{SRC_ROOT}/tests/fail_op.yaml',\n",
    ")\n",
    "def fail_op (message: str = \"Metric is below threshhold\"):\n",
    "    raise ValueError(message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    base_image=CONTAINER_URI,\n",
    "    output_component_file=f'{SRC_ROOT}/change-type.yaml',\n",
    ")\n",
    "def get_model_uri(model: Input[Model] ) -> str:\n",
    "    return model.uri\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "    name=\"view-test-pipeline\",\n",
    "    pipeline_root=PIPELINE_ROOT,\n",
    ")\n",
    "def view_pipeline(\n",
    "    project_id: str = PROJECT_ID,\n",
    "    raw_dataset: str = 'gs://bench-datasets/jena_climate_2009_2016.csv',\n",
    "    staging_bucket: str = 'gs://automl-samples',\n",
    "    mae_cutoff: float = 0.0,\n",
    "    model_display_name: str = 'forecast-custom',\n",
    "    context_window: int = 24,\n",
    "    experiment_prefix: str = 'weather-prediction-'\n",
    "):\n",
    "    preprocess_task = view_preprocess(\n",
    "        project_id=project_id,\n",
    "        raw_dataset=raw_dataset\n",
    "    )\n",
    "    train_task = view_train(\n",
    "        project_id=project_id,\n",
    "        input_dataset=preprocess_task.outputs[\"out_dataset\"],\n",
    "        context_window=context_window,\n",
    "        experiment_prefix=experiment_prefix,\n",
    "        staging_bucket=staging_bucket\n",
    "    )\n",
    "    with dsl.Condition(train_task.outputs['output'] > mae_cutoff , name=\"mae_test\"):\n",
    "        get_model_task = get_model_uri(train_task.outputs['model'])\n",
    "        model_upload_op = gcc_aip.ModelUploadOp(\n",
    "            project=project_id,\n",
    "            display_name=model_display_name,\n",
    "            artifact_uri=get_model_task.outputs['output'],\n",
    "            serving_container_image_uri=\"gcr.io/cloud-aiplatform/prediction/tf2-cpu.2-2:latest\",\n",
    "            serving_container_environment_variables={\"NOT_USED\": \"NO_VALUE\"},\n",
    "        )\n",
    "        model_upload_op.after(train_task)\n",
    "        endpoint_create_op = gcc_aip.EndpointCreateOp(\n",
    "            project=project_id,\n",
    "            display_name=\"pipelines-created-endpoint\",\n",
    "        )\n",
    "        model_deploy_op = gcc_aip.ModelDeployOp(  # noqa: F841\n",
    "            project=project_id,\n",
    "            endpoint=endpoint_create_op.outputs[\"endpoint\"],\n",
    "            model=model_upload_op.outputs[\"model\"],\n",
    "            deployed_model_display_name=model_display_name,\n",
    "            machine_type=\"n1-standard-4\",\n",
    "        )\n",
    "    with dsl.Condition(train_task.outputs['output'] < mae_cutoff , name=\"Low_Quality\"):\n",
    "        fail_task = fail_op()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kfp.v2 import compiler as v2compiler\n",
    "v2compiler.Compiler().compile(pipeline_func=view_pipeline,\n",
    "                              package_path='view_pipeline_spec.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kfp.v2.google.client import AIPlatformClient  # noqa: F811\n",
    "\n",
    "api_client = AIPlatformClient(\n",
    "    project_id=PROJECT_ID, \n",
    "    region=REGION, \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "See the Pipeline job <a href=\"https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/view-test-pipeline-20210602174252?project=pytorch-tpu-nfs\" target=\"_blank\" >here</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = api_client.create_run_from_job_spec(\n",
    "    job_spec_path=\"view_pipeline_spec.json\",\n",
    "    pipeline_root=PIPELINE_ROOT,\n",
    "    enable_caching=True,\n",
    "    parameter_values={\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Pipeline Run Failled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-0ca41bda2433>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mview_demo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_pipeline_status\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcheck_pipeline_status\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcheck_pipeline_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi_client\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/ml-ops-patterns/view_demo/utils/check_pipeline_status.py\u001b[0m in \u001b[0;36mcheck_pipeline_status\u001b[0;34m(api_client, result)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mpipeline_run_status\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapi_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'state'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpipeline_run_status\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'PIPELINE_STATE_FAILED'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Pipeline Run Failled\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mpipeline_run_status\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'PIPELINE_STATE_SUCCEEDED'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Pipeline Run Finished\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Pipeline Run Failled"
     ]
    }
   ],
   "source": [
    "from view_demo.utils.check_pipeline_status import check_pipeline_status\n",
    "check_pipeline_status(api_client, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Pipeline Run Failled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-f8eac4fc600f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mpipeline_run_status\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapi_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'state'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpipeline_run_status\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'PIPELINE_STATE_FAILED'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Pipeline Run Failled\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mpipeline_run_status\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'PIPELINE_STATE_SUCCEEDED'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Pipeline Run Finished\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Pipeline Run Failled"
     ]
    }
   ],
   "source": [
    "import time\n",
    "while True:\n",
    "    pipeline_run_status = api_client.get_job(result['name'].split('/')[-1])['state'] \n",
    "    if pipeline_run_status == 'PIPELINE_STATE_FAILED':\n",
    "        raise ValueError(\"Pipeline Run Failled\")\n",
    "    elif pipeline_run_status == 'PIPELINE_STATE_SUCCEEDED':\n",
    "        print(\"Pipeline Run Finished\")\n",
    "        break\n",
    "    else:\n",
    "        time.sleep(60) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "kfp.v2.google.client.client.AIPlatformClient"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(api_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:Mean Error is:0.12\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "val_mae = 0.12\n",
    "logging.info(f\"Mean Error is:{val_mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = np.float64(3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(float(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-3-gpu.2-3.m55",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-3-gpu.2-3:m55"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

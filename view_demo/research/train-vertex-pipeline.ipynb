{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import NamedTuple\n",
    "\n",
    "\n",
    "from kfp import dsl\n",
    "from kfp.v2 import compiler\n",
    "from typing import NamedTuple\n",
    "from kfp.v2 import dsl\n",
    "from kfp.v2.dsl import (\n",
    "    component,\n",
    "    InputPath,\n",
    "    OutputPath,\n",
    "    Input,\n",
    "    Output,\n",
    "    Artifact,\n",
    "    Dataset,\n",
    "    Model,\n",
    "    ClassificationMetrics,\n",
    "    Metrics,\n",
    ")\n",
    "\n",
    "from kfp.v2.google.client import AIPlatformClient\n",
    "from view_demo.utils import get_project_id\n",
    "from google_cloud_pipeline_components import aiplatform as gcc_aip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = get_project_id()\n",
    "REGION = 'us-central1'\n",
    "CONTAINER_URI = 'gcr.io/pytorch-tpu-nfs/test-custom-container'\n",
    "SRC_ROOT = '..'\n",
    "PIPELINE_ROOT = 'gs://automl-samples/pipelines/staging'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    base_image=CONTAINER_URI,\n",
    "    output_component_file=f'{SRC_ROOT}/preprocess/preprocess.yaml',\n",
    ")\n",
    "def view_preprocess(\n",
    "    project_id: str,\n",
    "    raw_dataset: str,\n",
    "    out_dataset: OutputPath(),\n",
    "):\n",
    "    from view_demo.preprocess import create_dataset\n",
    "    bq_path = create_dataset(project_id=project_id, csv_path=raw_dataset)\n",
    "    with open(out_dataset, 'w') as f:\n",
    "        f.write(bq_path)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_mae: OutputPath(float),\n",
    "@component(\n",
    "    base_image=CONTAINER_URI,\n",
    "    output_component_file=f'{SRC_ROOT}/train/train.yaml',\n",
    ")\n",
    "def view_train(\n",
    "    project_id: str,\n",
    "    input_dataset_path: InputPath(),\n",
    "    metrics: Output[Metrics],\n",
    "    model: Output[Model],\n",
    "    experiment_prefix: str ,\n",
    "    staging_bucket: str = 'gs://automl-samples',\n",
    "    context_window: int = 24\n",
    "  \n",
    ") -> float :\n",
    "    print(locals())\n",
    "    from google.cloud import aiplatform\n",
    "    from datetime import datetime\n",
    "    import logging\n",
    "    with open(input_dataset_path) as f:\n",
    "        logging.info(f\"input_dataset is: {f.read()}\")\n",
    "    # Create and experiment tag\n",
    "    TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "    experiment_id = experiment_prefix + TIMESTAMP\n",
    "    run_id = f'context-window-{context_window}'\n",
    "    # Init AI Platform\n",
    "    aiplatform.init(\n",
    "        project=project_id,\n",
    "        staging_bucket=staging_bucket,\n",
    "        experiment=experiment_id\n",
    "    )\n",
    "\n",
    "    # Define the custom training job\n",
    "    job = aiplatform.CustomContainerTrainingJob(\n",
    "        display_name=\"view-training\",\n",
    "        container_uri='gcr.io/pytorch-tpu-nfs/test-custom-trainer:latest',\n",
    "        model_serving_container_image_uri=\"gcr.io/cloud-aiplatform/prediction/tf2-cpu.2-2:latest\",\n",
    "    )\n",
    "    logging.info(f\"Type of experiment_id :{type(experiment_id)}\")\n",
    "    logging.info(f\"Type of staging_bucket :{type(staging_bucket)}\")\n",
    "    logging.info(f\"Type of context_window :{type(context_window)}\")\n",
    "    model_obj = job.run(\n",
    "        replica_count=1, \n",
    "        model_display_name=\"temp-prediction\",\n",
    "        args=[\n",
    "            f'--experiment-id={experiment_id}', \n",
    "            f'--staging-bucket={staging_bucket}',\n",
    "            f'--context-window={context_window}'\n",
    "        ],\n",
    "        environment_variables={'AIP_MODEL_DIR': model.uri},\n",
    "        base_output_dir=os.path.dirname(model.uri)\n",
    "    )\n",
    "    \n",
    "    metrics_df = aiplatform.get_experiment_df(experiment_id)\n",
    "    val_mae = metrics_df.loc[metrics_df['run_name'] == run_id]['metric.val_mae'].values[-1]\n",
    "    val_mae = float(val_mae)\n",
    "    metrics.log_metric('val_mae', val_mae)\n",
    "    logging.info(f\"Mean Error is:{val_mae}\")\n",
    "    return val_mae\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    base_image=CONTAINER_URI,\n",
    "    output_component_file=f'{SRC_ROOT}/tests/fail_op.yaml',\n",
    ")\n",
    "def fail_op (message: str = \"Metric is below threshhold\"):\n",
    "    raise ValueError(message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    base_image=CONTAINER_URI,\n",
    "    output_component_file=f'{SRC_ROOT}/change-type.yaml',\n",
    ")\n",
    "def get_model_uri(model: Input[Model] ) -> str:\n",
    "    return model.uri\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "    name=\"view-test-pipeline\",\n",
    "    pipeline_root=PIPELINE_ROOT,\n",
    ")\n",
    "def view_pipeline(\n",
    "    project_id: str = PROJECT_ID,\n",
    "    raw_dataset: str = 'gs://bench-datasets/jena_climate_2009_2016.csv',\n",
    "    staging_bucket: str = 'gs://automl-samples',\n",
    "    mae_cutoff: float = 0.0,\n",
    "    model_display_name: str = 'forecast-custom',\n",
    "    context_window: int = 24,\n",
    "    experiment_prefix: str = 'weather-prediction-'\n",
    "):\n",
    "    preprocess_task = view_preprocess(\n",
    "        project_id=project_id,\n",
    "        raw_dataset=raw_dataset\n",
    "    )\n",
    "    train_task = view_train(\n",
    "        project_id=project_id,\n",
    "        input_dataset=preprocess_task.outputs[\"out_dataset\"],\n",
    "        context_window=context_window,\n",
    "        experiment_prefix=experiment_prefix,\n",
    "        staging_bucket=staging_bucket\n",
    "    )\n",
    "    #train_task.execution_options.caching_strategy.max_cache_staleness = \"P0D\"\n",
    "\n",
    "    with dsl.Condition(train_task.outputs['output'] > mae_cutoff , name=\"mae_test\"):\n",
    "        get_model_task = get_model_uri(train_task.outputs['model'])\n",
    "        model_upload_op = gcc_aip.ModelUploadOp(\n",
    "            project=project_id,\n",
    "            display_name=model_display_name,\n",
    "            artifact_uri=get_model_task.outputs['output'],\n",
    "            serving_container_image_uri=\"gcr.io/cloud-aiplatform/prediction/tf2-cpu.2-2:latest\",\n",
    "            serving_container_environment_variables={\"NOT_USED\": \"NO_VALUE\"},\n",
    "        )\n",
    "        model_upload_op.after(train_task)\n",
    "        endpoint_create_op = gcc_aip.EndpointCreateOp(\n",
    "            project=project_id,\n",
    "            display_name=\"pipelines-created-endpoint\",\n",
    "        )\n",
    "        model_deploy_op = gcc_aip.ModelDeployOp(  # noqa: F841\n",
    "            project=project_id,\n",
    "            endpoint=endpoint_create_op.outputs[\"endpoint\"],\n",
    "            model=model_upload_op.outputs[\"model\"],\n",
    "            deployed_model_display_name=model_display_name,\n",
    "            machine_type=\"n1-standard-4\",\n",
    "        )\n",
    "    with dsl.Condition(train_task.outputs['output'] < mae_cutoff , name=\"Low_Quality\"):\n",
    "        fail_task = fail_op()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kfp.v2 import compiler as v2compiler\n",
    "v2compiler.Compiler().compile(pipeline_func=view_pipeline,\n",
    "                              package_path='view_pipeline_spec.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kfp.v2.google.client import AIPlatformClient  # noqa: F811\n",
    "\n",
    "api_client = AIPlatformClient(\n",
    "    project_id=PROJECT_ID, \n",
    "    region=REGION, \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "See the Pipeline job <a href=\"https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/view-test-pipeline-20210608045753?project=pytorch-tpu-nfs\" target=\"_blank\" >here</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = api_client.create_run_from_job_spec(\n",
    "    job_spec_path=\"view_pipeline_spec.json\",\n",
    "    pipeline_root=PIPELINE_ROOT,\n",
    "    enable_caching=False,\n",
    "    parameter_values={\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline Run Finished\n"
     ]
    }
   ],
   "source": [
    "from view_demo.utils.check_pipeline_status import check_pipeline_status\n",
    "check_pipeline_status(api_client, result)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-3-gpu.2-3.m55",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-3-gpu.2-3:m55"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

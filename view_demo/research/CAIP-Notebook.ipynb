{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id = 'pytorch-tpu-nfs'\n",
    "dataset_id = 'view_dataset'\n",
    "table_id = 'weather_time_series'\n",
    "experiment_id = 'weather-exp'\n",
    "staging_bucket = 'gs://automl-samples'\n",
    "location='us-central1'\n",
    "context_window = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client creating using default project: pytorch-tpu-nfs\n",
      "Dataset view_dataset already exists\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from google.cloud import bigquery\n",
    "from google.cloud.exceptions import NotFound\n",
    "\n",
    "import tempfile\n",
    "import argparse\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from view_demo.utils import get_project_id\n",
    "csv_path = 'gs://bench-datasets/jena_climate_2009_2016.csv'\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Convert to hourly dataset\n",
    "# slice [start:stop:step], starting from index 5 take every 6th record.\n",
    "df = df[5::6]\n",
    "\n",
    "# Clean Data\n",
    "wv = df['wv (m/s)']\n",
    "bad_wv = wv == -9999.0\n",
    "wv[bad_wv] = 0.0\n",
    "\n",
    "max_wv = df['max. wv (m/s)']\n",
    "bad_max_wv = max_wv == -9999.0\n",
    "max_wv[bad_max_wv] = 0.0\n",
    "\n",
    "# The above inplace edits are reflected in the DataFrame\n",
    "df['wv (m/s)'].min()\n",
    "\n",
    "\n",
    "# Rename Columns to comply with BQ\n",
    "df.rename(columns={\n",
    "    'p (mbar)': 'p__mbar',\n",
    "    'T (degC)': 'T__degC',\n",
    "    'Tpot (K)': 'Tpot__K',\n",
    "    'Tdew (degC)': 'Tdew__degC',\n",
    "    'rh (%)': 'rh__percent',\n",
    "    'VPmax (mbar)': 'VPmax__mbar' ,\n",
    "    'VPact (mbar)': 'VPact__mbar',\n",
    "    'VPdef (mbar)': 'VPdef__mbar',\n",
    "    'sh (g/kg)': 'sh__g_per_kg',\n",
    "    'H2OC (mmol/mol)': 'H2OC__mmol_per_mol',\n",
    "    'rho (g/m**3)': 'rho__gm_per_cubic_m',\n",
    "    'max Wx': 'max_Wx',\n",
    "    'max Wy': 'max_Wy',\n",
    "    'Day sin': 'Day_sin',\n",
    "    'Day cos': 'Day_cos',\n",
    "    'Year sin': 'Year_sin',\n",
    "    'Year cos': 'Year_cos',\n",
    "    'Date Time': 'Date_Time',\n",
    "    'wv (m/s)' : 'wv__m_per_s',\n",
    "    'max. wv (m/s)': 'max_w__vm_per_s',\n",
    "    'wd (deg)': 'wd__deg'\n",
    "\n",
    "}, inplace=True)\n",
    "\n",
    "# Write to BQ\n",
    "client = bigquery.Client(location=\"us-central1\", project=project_id)\n",
    "print(\"Client creating using default project: {}\".format(client.project))\n",
    "\n",
    "try:\n",
    "    dataset = client.get_dataset(dataset_id)  # Make an API request.\n",
    "    print(\"Dataset {} already exists\".format(dataset_id))\n",
    "except NotFound:\n",
    "    print(\"Dataset {} is not found, Creating..\".format(dataset_id))\n",
    "    dataset = client.create_dataset(dataset_id)\n",
    "\n",
    "table_ref = dataset.table(table_id)\n",
    "\n",
    "job_config = bigquery.LoadJobConfig(\n",
    "    destination_table_description=table_ref,\n",
    "    autodetect=True,\n",
    ")\n",
    "# Overwrite the table if already exists\n",
    "job_config.write_disposition = 'WRITE_TRUNCATE'\n",
    "\n",
    "#job = client.load_table_from_dataframe(df, table_ref, location=\"us-central1\")\n",
    "#job.result()  # Waits for table load to complete.\n",
    "#print(\"Loaded dataframe to {}\".format(table_ref.path))\n",
    "\n",
    "#return table_ref.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataframe to /projects/pytorch-tpu-nfs/datasets/view_dataset/tables/weather_time_series\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/projects/pytorch-tpu-nfs/datasets/view_dataset/tables/weather_time_series'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape\n",
    "job = client.load_table_from_dataframe(df, table_ref, location=\"us-central1\")\n",
    "job.result()  # Waits for table load to complete.\n",
    "print(\"Loaded dataframe to {}\".format(table_ref.path))\n",
    "\n",
    "table_ref.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'WindowGenerator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-18e19ffc0603>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m wide_window = WindowGenerator(\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0minput_width\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontext_window\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_width\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontext_window\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshift\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mlabel_columns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'T__degC'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'WindowGenerator' is not defined"
     ]
    }
   ],
   "source": [
    "run_id = f'context-window-{context_window}'\n",
    "from view_demo.train.custom_tf_trainer import trainer\n",
    "experiment_tracking_on = staging_bucket is not None\n",
    "trainer = trainer(\n",
    "   project_id,\n",
    "   location,\n",
    "   dataset_id,\n",
    "   table_id\n",
    ")\n",
    "trainer.read_dataset()\n",
    "train_df, val_df, test_df = trainer.create_split()\n",
    "wide_window = WindowGenerator(\n",
    "    input_width=context_window, label_width=context_window, shift=1,\n",
    "    label_columns=['T__degC'],\n",
    "    train_df=train_df,\n",
    "    test_df=test_df,\n",
    "    val_df=val_df)\n",
    "history = trainer.compile_and_fit(linear, wide_window)\n",
    "if experiment_tracking_on:\n",
    "    from google.cloud import aiplatform\n",
    "    aiplatform.init(\n",
    "        project=project_id,\n",
    "        staging_bucket=staging_bucket,\n",
    "        experiment=experiment_id\n",
    "    )\n",
    "    aiplatform.start_run(run=run_id)\n",
    "    aiplatform.log_metrics({\"val_loss\": history.history['val_loss'][-1]})\n",
    "    aiplatform.log_metrics({\"val_mae\": history.history['val_mean_absolute_error'][-1]})\n",
    "    aiplatform.log_metrics({\"train_loss\": history.history['loss'][-1]})\n",
    "    aiplatform.log_metrics({\"train_mae\": history.history['mean_absolute_error'][-1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [12.012874603271484, 12.001683235168457], 'mean_absolute_error': [1.9278665781021118, 1.924259901046753], 'val_loss': [5.564371585845947, 5.717701435089111], 'val_mean_absolute_error': [1.4334169626235962, 1.4232121706008911]}\n"
     ]
    }
   ],
   "source": [
    "print(history.history)\n",
    "aiplatform.log_metrics({\"train_loss\": history.history['loss'][-1]})\n",
    "aiplatform.log_metrics({\"train_mae\": history.history['mean_absolute_error'][-1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>run_name</th>\n",
       "      <th>metric.val_mae</th>\n",
       "      <th>metric.val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>weather-exp</td>\n",
       "      <td>window-24</td>\n",
       "      <td>1.422686</td>\n",
       "      <td>5.575446</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  experiment_name   run_name  metric.val_mae  metric.val_loss\n",
       "0     weather-exp  window-24        1.422686         5.575446"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aiplatform.init(project=project_id, location=location, experiment=experiment_id)\n",
    "metrics_df = aiplatform.get_experiment_df()\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_df = aiplatform.get_experiment_df(experiment='weather-exp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4232121706008911"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_df.loc[exp_df['run_name'] == run_id]['metric.val_mae'].values[-1]\n",
    "#.at[0,'metric.val_mae']\n",
    "    \n",
    "    #['metric.val_mae'] > 1.5).any():\n",
    "    #print(\"HIT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from google.cloud import aiplatform\n",
    "#aiplatform.init(project=project_id, staging_bucket=staging_bucket, experiment=experiment_id)\n",
    "aiplatform.log_metrics({\"val_loss\": history.history['val_loss'][-1]})\n",
    "aiplatform.log_metrics({\"val_mae\": history.history['val_mean_absolute_error'][-1]})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-cloud-aiplatform\n",
      "  Downloading google_cloud_aiplatform-1.0.1-py2.py3-none-any.whl (1.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.8 MB 8.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: google-cloud-bigquery<3.0.0dev,>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-aiplatform) (1.28.0)\n",
      "Requirement already satisfied, skipping upgrade: packaging>=14.3 in /opt/conda/lib/python3.7/site-packages (from google-cloud-aiplatform) (20.4)\n",
      "Requirement already satisfied, skipping upgrade: google-api-core[grpc]<2.0.0dev,>=1.22.2 in /opt/conda/lib/python3.7/site-packages (from google-cloud-aiplatform) (1.26.1)\n",
      "Collecting google-cloud-storage<2.0.0dev,>=1.32.0\n",
      "  Downloading google_cloud_storage-1.38.0-py2.py3-none-any.whl (103 kB)\n",
      "\u001b[K     |████████████████████████████████| 103 kB 41.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: proto-plus>=1.10.1 in /home/jupyter/.local/lib/python3.7/site-packages (from google-cloud-aiplatform) (1.13.0)\n",
      "Requirement already satisfied, skipping upgrade: google-cloud-core<2.0dev,>=1.4.1 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform) (1.6.0)\n",
      "Requirement already satisfied, skipping upgrade: six<2.0.0dev,>=1.13.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: google-resumable-media<2.0dev,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform) (1.2.0)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=14.3->google-cloud-aiplatform) (2.4.7)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.12.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.22.2->google-cloud-aiplatform) (3.13.0)\n",
      "Requirement already satisfied, skipping upgrade: pytz in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.22.2->google-cloud-aiplatform) (2020.1)\n",
      "Requirement already satisfied, skipping upgrade: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.22.2->google-cloud-aiplatform) (2.24.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools>=40.3.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.22.2->google-cloud-aiplatform) (49.6.0.post20200814)\n",
      "Requirement already satisfied, skipping upgrade: googleapis-common-protos<2.0dev,>=1.6.0 in /home/jupyter/.local/lib/python3.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.22.2->google-cloud-aiplatform) (1.52.0)\n",
      "Requirement already satisfied, skipping upgrade: google-auth<2.0dev,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.22.2->google-cloud-aiplatform) (1.27.1)\n",
      "Requirement already satisfied, skipping upgrade: grpcio<2.0dev,>=1.29.0; extra == \"grpc\" in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.22.2->google-cloud-aiplatform) (1.32.0)\n",
      "Requirement already satisfied, skipping upgrade: google-crc32c<2.0dev,>=1.0; python_version >= \"3.5\" in /home/jupyter/.local/lib/python3.7/site-packages (from google-resumable-media<2.0dev,>=0.6.0->google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform) (1.1.2)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.22.2->google-cloud-aiplatform) (1.25.10)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.22.2->google-cloud-aiplatform) (2.10)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.22.2->google-cloud-aiplatform) (2020.6.20)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.22.2->google-cloud-aiplatform) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /home/jupyter/.local/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.21.1->google-api-core[grpc]<2.0.0dev,>=1.22.2->google-cloud-aiplatform) (3.1.1)\n",
      "Requirement already satisfied, skipping upgrade: rsa<5,>=3.1.4; python_version >= \"3.6\" in /opt/conda/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.21.1->google-api-core[grpc]<2.0.0dev,>=1.22.2->google-cloud-aiplatform) (4.6)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.21.1->google-api-core[grpc]<2.0.0dev,>=1.22.2->google-cloud-aiplatform) (0.2.8)\n",
      "Requirement already satisfied, skipping upgrade: cffi>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from google-crc32c<2.0dev,>=1.0; python_version >= \"3.5\"->google-resumable-media<2.0dev,>=0.6.0->google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform) (1.14.1)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /opt/conda/lib/python3.7/site-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2.0dev,>=1.21.1->google-api-core[grpc]<2.0.0dev,>=1.22.2->google-cloud-aiplatform) (0.4.8)\n",
      "Requirement already satisfied, skipping upgrade: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi>=1.0.0->google-crc32c<2.0dev,>=1.0; python_version >= \"3.5\"->google-resumable-media<2.0dev,>=0.6.0->google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.20)\n",
      "Installing collected packages: google-cloud-storage, google-cloud-aiplatform\n",
      "  Attempting uninstall: google-cloud-storage\n",
      "    Found existing installation: google-cloud-storage 1.30.0\n",
      "    Uninstalling google-cloud-storage-1.30.0:\n",
      "      Successfully uninstalled google-cloud-storage-1.30.0\n",
      "  Attempting uninstall: google-cloud-aiplatform\n",
      "    Found existing installation: google-cloud-aiplatform 0.6.0\n",
      "    Uninstalling google-cloud-aiplatform-0.6.0:\n",
      "      Successfully uninstalled google-cloud-aiplatform-0.6.0\n",
      "\u001b[31mERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n",
      "\n",
      "We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n",
      "\n",
      "google-cloud-pipeline-components 0.1.0 requires google-cloud-aiplatform<1.0.0,>=0.7.1, but you'll have google-cloud-aiplatform 1.0.1 which is incompatible.\n",
      "tfx 0.25.0 requires pyarrow<0.18,>=0.17, but you'll have pyarrow 3.0.0 which is incompatible.\u001b[0m\n",
      "Successfully installed google-cloud-aiplatform-1.0.1 google-cloud-storage-1.38.0\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.1.2 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pip install google-cloud-aiplatform --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id = 'pytorch-tpu-nfs'\n",
    "staging_bucket = 'gs://automl-samples'\n",
    "location='us-central1'\n",
    "context_window = 24\n",
    "run_id = f'context-window-{context_window}'\n",
    "experiment_prefix = 'weather-exp'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:Resource weather-exp20210603231244 not found.\n",
      "INFO:root:Creating Resource weather-exp20210603231244\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "run() got an unexpected keyword argument 'tensorboard'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-165d70604ecc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;34mf'--context-window={context_window}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     ],\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mtensorboard\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'view-tensor-board'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m )\n\u001b[1;32m     33\u001b[0m \u001b[0mmetrics_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maiplatform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_experiment_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiment_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: run() got an unexpected keyword argument 'tensorboard'"
     ]
    }
   ],
   "source": [
    "from google.cloud import aiplatform\n",
    "from datetime import datetime\n",
    "\n",
    "# Create and experiment tag\n",
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "experiment_id = experiment_prefix + TIMESTAMP\n",
    "\n",
    "# Init AI Platform\n",
    "aiplatform.init(\n",
    "    project=project_id,\n",
    "    staging_bucket=staging_bucket,\n",
    "    experiment=experiment_id\n",
    ")\n",
    "\n",
    "# Define the custom training job\n",
    "job = aiplatform.CustomContainerTrainingJob(\n",
    "    display_name=\"view-training\",\n",
    "    container_uri='gcr.io/pytorch-tpu-nfs/test-custom-trainer:latest',\n",
    "    model_serving_container_image_uri=\"gcr.io/cloud-aiplatform/prediction/tf2-cpu.2-2:latest\",\n",
    ")\n",
    "\n",
    "\n",
    "model = job.run(\n",
    "    replica_count=1, \n",
    "    model_display_name=\"temp-prediction\",\n",
    "    args=[\n",
    "        f'--experiment-id={experiment_id}', \n",
    "        f'--staging-bucket={staging_bucket}',\n",
    "        f'--context-window={context_window}'\n",
    "    ]\n",
    ")\n",
    "metrics_df = aiplatform.get_experiment_df(experiment_id)\n",
    "#metrics_df.loc[exp_df['run_name'] == run_id]['metric.val_mae'].values[-1]\n",
    "\n",
    "print(metrics_df)\n",
    "out_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build  google-cloud-aiplatform-0.6.0.tar.gz  setup.py\tview_demo.egg-info\n",
      "docs   README.md\t\t\t     view_demo\n"
     ]
    }
   ],
   "source": [
    "!ls ../../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'123'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ.get('AIP_MODEL_DIR', \"123\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<google.cloud.aiplatform.models.Model object at 0x7fb381e09950> \n",
       "resource name: projects/64701051322/locations/us-central1/models/1968055444974862336"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_FutureManager__latest_future',\n",
       " '_FutureManager__latest_future_lock',\n",
       " '__abstractmethods__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_abc_impl',\n",
       " '_are_futures_done',\n",
       " '_complete_future',\n",
       " '_construct_sdk_resource_from_gapic',\n",
       " '_delete_method',\n",
       " '_deploy',\n",
       " '_empty_constructor',\n",
       " '_exception',\n",
       " '_gca_resource',\n",
       " '_get_and_validate_project_location',\n",
       " '_get_gca_resource',\n",
       " '_getter_method',\n",
       " '_instantiate_client',\n",
       " '_is_client_prediction_client',\n",
       " '_latest_future',\n",
       " '_list',\n",
       " '_list_method',\n",
       " '_list_with_local_order',\n",
       " '_raise_future_exception',\n",
       " '_resource_noun',\n",
       " '_submit',\n",
       " '_sync_gca_resource',\n",
       " '_sync_object_with_future_result',\n",
       " '_wait_on_export',\n",
       " 'api_client',\n",
       " 'batch_predict',\n",
       " 'client_class',\n",
       " 'create_time',\n",
       " 'credentials',\n",
       " 'delete',\n",
       " 'deploy',\n",
       " 'description',\n",
       " 'display_name',\n",
       " 'export_model',\n",
       " 'gca_resource',\n",
       " 'list',\n",
       " 'location',\n",
       " 'name',\n",
       " 'project',\n",
       " 'resource_name',\n",
       " 'supported_export_formats',\n",
       " 'update_time',\n",
       " 'upload',\n",
       " 'uri',\n",
       " 'wait']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(out_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gs://automl-samples/aiplatform-custom-training-2021-06-02-00:39:59.034/model'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_model.uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'google.cloud.aiplatform.base' has no attribute 'AiPlatformResourceNoun'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-e32bdbd4379c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle_cloud_pipeline_components\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maiplatform\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgcc_aip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/google_cloud_pipeline_components/aiplatform/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcloud\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maiplatform\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0maiplatform_sdk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle_cloud_pipeline_components\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maiplatform\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m __all__ = [\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/google_cloud_pipeline_components/aiplatform/utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m def get_forward_reference(\n\u001b[1;32m     46\u001b[0m     \u001b[0mannotation\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m ) -> Optional[aiplatform.base.AiPlatformResourceNoun]:\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0;34m\"\"\"Resolves forward references to AiPlatform Class.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'google.cloud.aiplatform.base' has no attribute 'AiPlatformResourceNoun'"
     ]
    }
   ],
   "source": [
    "from google_cloud_pipeline_components import aiplatform as gcc_aip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'google.cloud.aiplatform.base' has no attribute 'AiPlatformResourceNoun'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-e32bdbd4379c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle_cloud_pipeline_components\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maiplatform\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgcc_aip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/google_cloud_pipeline_components/aiplatform/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcloud\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maiplatform\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0maiplatform_sdk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle_cloud_pipeline_components\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maiplatform\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m __all__ = [\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/google_cloud_pipeline_components/aiplatform/utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m def get_forward_reference(\n\u001b[1;32m     46\u001b[0m     \u001b[0mannotation\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m ) -> Optional[aiplatform.base.AiPlatformResourceNoun]:\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0;34m\"\"\"Resolves forward references to AiPlatform Class.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'google.cloud.aiplatform.base' has no attribute 'AiPlatformResourceNoun'"
     ]
    }
   ],
   "source": [
    "from google_cloud_pipeline_components import aiplatform as gcc_aip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-3-gpu.2-3.m55",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-3-gpu.2-3:m55"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
